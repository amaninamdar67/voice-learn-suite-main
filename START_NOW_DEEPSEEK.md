# Start Using AI Tutor Now! ðŸš€

You already have Ollama and DeepSeek-R1:1.5B installed. Here's all you need to do:

## Step 1: Start Ollama Service

### Windows:
```bash
ollama serve
```

### Mac/Linux:
```bash
ollama serve
```

Keep this terminal/command window open.

---

## Step 2: Start Your Application

Open a new terminal/command prompt and run:
```bash
npm run dev
```

---

## Step 3: Use AI Tutor

1. Open your application in browser (usually http://localhost:5173)
2. Look for the ðŸ¤– button in the bottom-right corner
3. Click it
4. Start chatting!

---

## Features Available

âœ“ **Chat** - Ask questions and get AI responses
âœ“ **Voice Input** - Press SPACEBAR to use voice commands
âœ“ **Document Upload** - Upload PDFs or text files for analysis
âœ“ **Read Aloud** - Click "Read" to hear responses
âœ“ **Multiple Views** - Popup, Right Panel, or Fullscreen

---

## Troubleshooting

### "No response from AI"
â†’ Make sure `ollama serve` is running in a terminal

### "Cannot connect to Ollama"
â†’ Start Ollama with: `ollama serve`

### "Very slow first response"
â†’ Normal - the model loads into memory on first use
â†’ Subsequent responses are faster

---

## That's It!

You're all set. Just keep Ollama running and enjoy the AI Tutor! ðŸŽ‰

